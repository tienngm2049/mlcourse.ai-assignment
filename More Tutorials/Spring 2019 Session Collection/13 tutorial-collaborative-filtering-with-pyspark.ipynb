{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system based on PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial I am going to demonstrate how Spark MLlib can be used for movie recommendation task.\n",
    "\n",
    "First, let me start from problem statement: goal of any recommendation system is to analyze how users interact with existing system and make some recommendation of what they can buy, listen or watch in the future so that we can make our users happier, and hopefully, increase profitability of system we develop.\n",
    "\n",
    "There are several approaches to this task due to [wiki](https://en.wikipedia.org/wiki/Recommender_system): \n",
    "* Collaborative filtering \n",
    "methods are based on collecting and analyzing a large amount of information on users’ behaviors, activities or preferences and predicting what users will like based on their similarity to other users. A key advantage of the collaborative filtering approach is that it does not rely on machine analyzable content and therefore it is capable of accurately recommending complex items such as movies without requiring an \"understanding\" of the item itself. Collaborative filtering is based on the assumption that people who agreed in the past will agree in the future, and that they will like similar kinds of items as they liked in the past.\n",
    "* Content-based filtering\n",
    "methods are based on a description of the item and a profile of the user’s preferences.\n",
    "In a content-based recommender system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes. In other words, these algorithms try to recommend items that are similar to those that a user liked in the past (or is examining in the present). In particular, various candidate items are compared with items previously rated by the user and the best-matching items are recommended.\n",
    "* Hybrid recommender systems\n",
    "which is combining collaborative filtering and content-based filtering could be more effective in some cases. Hybrid approaches can be implemented in several ways: by making content-based and collaborative-based predictions separately and then combining them; by adding content-based capabilities to a collaborative-based approach (and vice versa); or by unifying the approaches into one mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work I will demonstrate how to use Collaborative Filtering approach using Spark MLlib. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my case I would like to recommend movies to users, based on dataset provided by [Megogo](https://megogo.net/ru) and competition they hosted at [Kaggle](https://www.kaggle.com/c/megogochallenge). \n",
    "\n",
    "I've been participated in this competiton during mlcourse and took 10th place out of 42 teams there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp \n",
    "#https://www.kaggle.com/getting-started/45288 - this helps some with 'no space left on device'\n",
    "\n",
    "#print(os.listdir(\"../input/megogochallenge/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying data so that you could undesrtand how it looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_start_datetime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>primary_video_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>vod_type</th>\n",
       "      <th>session_duration</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_os</th>\n",
       "      <th>player_position_min</th>\n",
       "      <th>player_position_max</th>\n",
       "      <th>time_cumsum_max</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>watching_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-01 00:00:02.135</td>\n",
       "      <td>21603820</td>\n",
       "      <td>27241033</td>\n",
       "      <td>9583642</td>\n",
       "      <td>9583642</td>\n",
       "      <td>svod</td>\n",
       "      <td>688</td>\n",
       "      <td>web</td>\n",
       "      <td>Windows_10</td>\n",
       "      <td>6940</td>\n",
       "      <td>6940</td>\n",
       "      <td>93</td>\n",
       "      <td>8198</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-01 00:00:02.232</td>\n",
       "      <td>35636970</td>\n",
       "      <td>10887511</td>\n",
       "      <td>24645936</td>\n",
       "      <td>24645936</td>\n",
       "      <td>advod</td>\n",
       "      <td>3174</td>\n",
       "      <td>mobile</td>\n",
       "      <td>android</td>\n",
       "      <td>599</td>\n",
       "      <td>3173</td>\n",
       "      <td>0</td>\n",
       "      <td>5297</td>\n",
       "      <td>0.5990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-01 00:00:06.961</td>\n",
       "      <td>78312976</td>\n",
       "      <td>15427448</td>\n",
       "      <td>25397362</td>\n",
       "      <td>23346676</td>\n",
       "      <td>advod</td>\n",
       "      <td>3054</td>\n",
       "      <td>tv</td>\n",
       "      <td>samsung</td>\n",
       "      <td>599</td>\n",
       "      <td>3052</td>\n",
       "      <td>3032</td>\n",
       "      <td>3052</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-01 00:00:11.044</td>\n",
       "      <td>122261599</td>\n",
       "      <td>12021384</td>\n",
       "      <td>5205267</td>\n",
       "      <td>22898606</td>\n",
       "      <td>svod</td>\n",
       "      <td>2400</td>\n",
       "      <td>tv</td>\n",
       "      <td>netcast</td>\n",
       "      <td>600</td>\n",
       "      <td>2400</td>\n",
       "      <td>2378</td>\n",
       "      <td>2638</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-01 00:00:14.054</td>\n",
       "      <td>53477088</td>\n",
       "      <td>65858458</td>\n",
       "      <td>14098190</td>\n",
       "      <td>14098190</td>\n",
       "      <td>advod</td>\n",
       "      <td>2481</td>\n",
       "      <td>tv</td>\n",
       "      <td>webos</td>\n",
       "      <td>137</td>\n",
       "      <td>4849</td>\n",
       "      <td>2316</td>\n",
       "      <td>5115</td>\n",
       "      <td>0.4850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_start_datetime         ...           watching_percentage\n",
       "0  2018-07-01 00:00:02.135         ...                        0.0839\n",
       "1  2018-07-01 00:00:02.232         ...                        0.5990\n",
       "2  2018-07-01 00:00:06.961         ...                        1.0000\n",
       "3  2018-07-01 00:00:11.044         ...                        0.9100\n",
       "4  2018-07-01 00:00:14.054         ...                        0.4850\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv('../input/megogochallenge/train_data_full.csv')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very important not only to recommend movies that user would like to watch. But to recommend movies which user will watch more than on half. It could be observed in `watching_percentage` column. \n",
    "\n",
    "Actually it was a goal of competition (to predict movies that will be watched more than on half). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feb0bd584a8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df['watching_percentage'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most movies are watched till the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evaluation metric MAP@10 is used for competiton - it's variations is very common metric for any recommendation tasks. More about it you could read [here](http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html).\n",
    "\n",
    "But in this tutorial I'll use RMSE, which is easier to understand for everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's move to PySpark. \n",
    "There is 2 ways to install it in Kaggle Kernels: \n",
    "* Run magic command, as in cell below\n",
    "* Or go to Packages and enter pyspark (it will take some time, but this will form your own version of docker and you'll no need to waste time while running next versions of kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.6/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: py4j==0.10.7 in /opt/conda/lib/python3.6/site-packages (from pyspark) (0.10.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install it locally or at jupyter server follow [this](https://medium.freecodecamp.org/how-to-set-up-pyspark-for-your-jupyter-notebook-7399dd3cb389) instruction. \n",
    "\n",
    "First, you have to install Java and Scala. Then set enviroment variables to launch Spark with Python3 and finally install pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now importing all needed spark modules. Pay attention how sc and spark variables were initialized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sql_func\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "sc = SparkContext('local') #https://stackoverflow.com/questions/30763951/spark-context-sc-not-defined\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read data in Spark format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = StructType([\n",
    "    StructField('session_start_datetime',TimestampType(), False),\n",
    "    StructField('user_id',IntegerType(), False),\n",
    "    StructField('user_ip',IntegerType(), False),\n",
    "    StructField('primary_video_id',IntegerType(), False),\n",
    "    StructField('video_id',IntegerType(), False),\n",
    "    StructField('vod_type',StringType(), False),\n",
    "    StructField('session_duration',IntegerType(), False),\n",
    "    StructField('device_type',StringType(), False),\n",
    "    StructField('device_os',StringType(), False),\n",
    "    StructField('player_position_min',LongType(), False),\n",
    "    StructField('player_position_max',LongType(), False),\n",
    "    StructField('time_cumsum_max',LongType(), False),\n",
    "    StructField('video_duration',IntegerType(), False),\n",
    "    StructField('watching_percentage',FloatType(), False)\n",
    "])\n",
    "final_stat = spark.read.csv(\n",
    "    '../input/megogochallenge/train_data_full.csv', header=True, schema=data_schema\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare data for model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (final_stat\n",
    "    .select(\n",
    "        'user_id',\n",
    "        'primary_video_id',\n",
    "        'watching_percentage',\n",
    "    )\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a `train_test_split`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = ratings.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](http://)Finally build an [ALS](https://dl.acm.org/citation.cfm?id=1608614) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7092173090577979\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=2, regParam=0.01, \n",
    "          userCol=\"user_id\", itemCol=\"primary_video_id\", ratingCol=\"watching_percentage\",\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=True)\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"watching_percentage\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look on parameters, and try to find any improvements. \n",
    "\n",
    "Parameters of ALS Model in PySpark realization are following: \n",
    "* **NumBlocks** is the number of blocks the users and items will be partitioned into in order to parallelize computation.\n",
    "* **rank** is the number of latent factors in the model.\n",
    "* **maxIter** is the maximum number of iterations to run.\n",
    "* **regParam** specifies the regularization parameter in ALS.\n",
    "* **implicitPrefs** specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n",
    "* **alpha** is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit or implicit? \n",
    "\n",
    "The standard approach to matrix factorization based collaborative filtering treats the entries in the user-item matrix as explicit preferences given by the user to the item, for example, users giving ratings to movies.\n",
    "\n",
    "As we see in our dataset we have a bunch of implicit information like `device_type`, `video_duration`, `device_os`. \n",
    "But let's try to use only explicit information and look on RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.42465506263708164\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=2, regParam=0.01, \n",
    "          userCol=\"user_id\", itemCol=\"primary_video_id\", ratingCol=\"watching_percentage\",\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=False) #changed param!\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"watching_percentage\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Our RMSE improved really well!\n",
    "But remember, if the rating matrix is derived from another source of information (i.e. it is inferred from other signals), you can set `implicitPrefs` to `True` to get better results. \n",
    "\n",
    "Could we do more? \n",
    "Let me increase `rank`, which is number of latent factor a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.400582274318481\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(rank=20, #10 was by default\n",
    "          maxIter=2, regParam=0.01,\n",
    "          userCol=\"user_id\", itemCol=\"primary_video_id\", ratingCol=\"watching_percentage\",\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=False)\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"watching_percentage\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our score is improved a bit, but not dramatically. \n",
    "\n",
    "Here I should say that I am a bit limited by Kaggle Kernels resources (Spark use a lot of RAM!) and of course it's better to experiment with parameters locally.\n",
    "\n",
    "General recommendations: \n",
    "* increase `maxIter` and `rank` checking them on CV of course (may be time and RAM consuming). \n",
    "* don't forget about regularization parametr\n",
    "\n",
    "Okay, now I want to output the recommendations itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 188 ms, sys: 100 ms, total: 288 ms\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.count()\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "movieRecs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Spark data to well-known Pandas could be done easily with `toPandas()` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401553, 2)\n",
      "(7220, 2)\n"
     ]
    }
   ],
   "source": [
    "userRecs_df = userRecs.toPandas()\n",
    "print(userRecs_df.shape)\n",
    "\n",
    "movieRecs_df = movieRecs.toPandas()\n",
    "print(movieRecs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7340</td>\n",
       "      <td>[(27987803, 2.907897472381592), (28900883, 2.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28577</td>\n",
       "      <td>[(15729968, 2.7276458740234375), (18544535, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38723</td>\n",
       "      <td>[(19875588, 2.8586254119873047), (24694479, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119432</td>\n",
       "      <td>[(13028255, 2.3740458488464355), (13071722, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188122</td>\n",
       "      <td>[(32614008, 3.399120807647705), (10108953, 3.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    recommendations\n",
       "0     7340  [(27987803, 2.907897472381592), (28900883, 2.5...\n",
       "1    28577  [(15729968, 2.7276458740234375), (18544535, 2....\n",
       "2    38723  [(19875588, 2.8586254119873047), (24694479, 2....\n",
       "3   119432  [(13028255, 2.3740458488464355), (13071722, 2....\n",
       "4   188122  [(32614008, 3.399120807647705), (10108953, 3.2..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRecs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see movie recommendation and it's score by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_video_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2503270</td>\n",
       "      <td>[(50245367, 1.7377479076385498), (69026283, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16598040</td>\n",
       "      <td>[(30700999, 3.5905983448028564), (90627429, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26049640</td>\n",
       "      <td>[(46116994, 1.8512648344039917), (47528753, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2801091</td>\n",
       "      <td>[(103819960, 2.200399398803711), (26814334, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20929121</td>\n",
       "      <td>[(33491259, 2.3538997173309326), (22162048, 2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   primary_video_id                                    recommendations\n",
       "0           2503270  [(50245367, 1.7377479076385498), (69026283, 1....\n",
       "1          16598040  [(30700999, 3.5905983448028564), (90627429, 3....\n",
       "2          26049640  [(46116994, 1.8512648344039917), (47528753, 1....\n",
       "3           2801091  [(103819960, 2.200399398803711), (26814334, 2....\n",
       "4          20929121  [(33491259, 2.3538997173309326), (22162048, 2...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieRecs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see recommendation and it's score by each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, collaborative filtering is one of the most popular approach to build recommendation system. \n",
    "Movie recommendation task become extremely popular after [Netflix competition](https://en.wikipedia.org/wiki/Netflix_Prize) with one million dollar prize, which push Machine Learning a lot in recommender systems field. \n",
    "\n",
    "With PySpark, we could get great results in this task just in a few lines of code. \n",
    "In production, new problems appeared, on of them is **cold start** problem when we have no any historical information about user, but still have to recommend something.\n",
    "But that's more than this tutorial would like to cover.\n",
    "\n",
    "Hope this small intro was useful, feel free to criticize, discuss, and maybe upvote:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Spark docs](https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html)\n",
    "* [Megogo challenge baselines](https://github.com/SantyagoSeaman/megogo_challenge_solutions)\n",
    "* [More on ranking metrics](https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics)\n",
    "* [How does netflix recommeder system works](https://help.netflix.com/en/node/100639)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
